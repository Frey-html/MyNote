3190102196 展翼飞
***
**白盒模型逆向攻击和黑盒模型反演攻击各适用于什么样的场景？课程中的模型逆向攻击都
需要最终的输出向量，是否有可能进行仅获得标签的模型逆向攻击？**
1. **白盒模型逆向攻击**：攻击者知道模型结构、参数，以便攻击者可以更好地通过模型的输出反推训练集中某条目标数据的部分或全部属性值。将模型逆向攻击问题转变为一个优化问题，优化目标为使逆向数据的输出向量与目标数据的输出向量差异尽可能地小，即假如攻击者获得了属于某一类别的输出向量，那么他可以利用梯度下降的方法使逆向的数据经过目标模型的推断后，仍然能得到同样的输出向量
2. **黑盒模型反演攻击**：攻击者只能访问目标模型，得到输出向量，不知道模型的结构、参数、数据集知道模型训练数据集的大致分布，可以从更“通用”的数据分布中采样，知道目标模型输入和输出数据结构，访问黑盒模型得到的输出不是完整向量，是截断向量
3. **仅获得标签**：如果攻击者仅能够获取模型的输出标签，则无法通过输出向量判断模型的输出分布，无法通过这种分布判断训练集对模型影响带来的倾向性，不能功过输出向量使逆向数据与目标数据通过梯度下降发拟合，无法进行逆向攻击。

**模型窃取攻击中，替代模型方法异常的大量查询不仅仅会增加窃取成本，更会被模型拥有
者检测出来，你能想到什么解决方法来避免过多的向目标模型查询？**
1. **采样查询**：避免在短时间内频繁向目标模型发送大量查询，而是通过采样的方式间隔一段时间发送查询请求。这样做可以减少对目标模型的负载，同时降低被检测到的风险。
2. **优化查询策略**：设计更加智能的查询策略，减少不必要的查询次数。可以利用模型的输出结果进行反馈，指导下一步查询的方向，以达到更高效的窃取。
3. **使用代理或者混淆技术**：利用代理服务器或者混淆技术隐藏真实的查询来源，使得查询看起来来自不同的地理位置或者网络环境，从而降低被检测到的可能性。
4. **限制查询频率**：对于模型的查询请求进行频率限制，确保在一定时间内不会发送过多的查询请求，避免引起目标模型拥有者的怀疑。

**在MemGuard的防御场景下，如果攻击者在输入图像上添加扰动可以破坏单次随机的设定，
你认为防御者应该如何应对？**
1. **增加噪声容忍度**：通过增加模型对输入的噪声容忍度，使得模型能够更好地处理输入图像中的轻微扰动，从而降低攻击者添加扰动的影响。
2. **多次检测和验证**：进行多次检测和验证，而不仅仅依赖于单次随机设定。通过多次运行模型或者应用不同的随机设定，可以降低攻击者成功的概率。
3. **集成多个防御机制**：采用多种防御机制的集成，以增加模型的鲁棒性。例如，可以结合对抗训练、输入预处理、模型融合等技术，从多个角度对抗攻击。

**数字水印可以保护模型版权，但是无法防御攻击者窃取模型的过程，是否有方法可以直接
防止模型被窃取？**
1. **模型加密**：对模型的参数和结构进行加密处理，使得模型在传输和存储过程中都能够得到保护。只有经过授权的用户才能够解密和使用模型，从而防止未经授权的访问和窃取。
2. **硬件保护**：将模型部署在安全的硬件环境中，如可信执行环境或安全芯片中，以确保模型在运行时的安全性，防止恶意用户通过物理手段获取模型信息。