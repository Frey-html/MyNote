#### 培训
* 并行编程与gpu编程模型
* 理解GPU Shader Hardware概念

* GPGPU 通用gpu，没有图形管线，没有几何计算和光栅化，增加了更多计算单元（更多SIMD core），适用于人工智能的并行计算


![[95c423deac5f9ed37dc79c0b109df93a.jpg]]
* 程序如何在GPU上运行：
	* MACA:沐曦开发的CUDA替代
	* 核函数才是跑在gpu上的内容，其他跑在cpu上，利用异步编程。在cpu编程部分利用api分配空间，拷贝内存至gpu，调用核函数。在gpu运行完成后再将gpu device上的结果拷贝到cpu上验证。
	* Grid - WorkGroup（ThreadBlock）- WorkItem（Thread和软件线程不是一个概念）
	   Wave/Warp 在硬件处理时以多少WorkItem（Thread）为单位来处理。在沐曦的架构里，一条指令可以处理64个thread，绑定到一个寄存器组里，将处理一组thread的行为称为Wave/Warp
	 * STREG（single thread register）与 MTREG（multi thread Register） XMSK(ExecutionMusk)控制SIMD指令中寄存器每一thread是否执行操作
	![[lQDPJxBI-LoeZvjNAj7NBP-wxMHQhvCtVwIFLE1ZZMxSAA_1279_574.jpg]]
	* 一个GPU里面设计了8个相同的DPC负责完成任务，可以被阉割。同一个WorkGrop中的多个Wave会被分给一个DPC中的同一个AP中多次执行![[lQDPJwIS_h5C4tjNAj7NBP-wtIFIEsGXdZ0FLE62452yAA_1279_574.jpg]]
	* Shader subsystem：ISU(Instruction scheduler) PEU（Processor element）SL1(Scalar L1  cache) WSM（workgroup shared memory） VLS（vector load / store）类似五级流水cpu架构![[lQDPJx8ZkHv7ytjNAj7NBP-wmYZzdxkEKgUFLE82Ky4tAA_1279_574.jpg]]![[lQDPJwTqlqjRIRjNAj7NBP-wddAuVgKLrFYFLE_mc4k3AA_1279_574.jpg]]![[lQDPJxvwHUznBljNAj7NBP-w2p15y97E55gFLFBKjmofAA_1279_574.jpg]]L2是内存，先读到L1缓存中再读到ap中